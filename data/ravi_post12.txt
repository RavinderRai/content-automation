Complexity is a terrible starting point.

Jumping straight to LLMs when the problem could be solved with something simpler, faster, and cheaper is never a good idea.

Much better to start simple, then add complexity only if you need it.

Take for example:

ðŸ”¹ Tabular prediction: Donâ€™t start with GPT for forecasting or churn. XGBoost gets you 90% of the way there - and you can always revisit if they fall short.

ðŸ”¹ Simple classification: Donâ€™t start with GPT for spam detection, sentiment, or categorization. Logistic regression or a small transformer usually does the trick.

ðŸ”¹ Heuristics & rules: Donâ€™t start with GPT where a regex or SQL filter works. It gets you shipping fast, and you can layer in ML later if the use case matures.

LLMs are powerful - but they should be step 3, not step 1.

Complexity isnâ€™t how you start. Itâ€™s what you earn.
